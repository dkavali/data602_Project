{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random-Forest-TimeBased-FInal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjnKYECERHSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.3.4/spark-2.3.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.4-bin-hadoop2.7.tgz \n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxqEuYafS3me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-mAtthWTHae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csShwoetTNFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "#spark imports\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import DataFrame\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import format_number, when, col, array, udf, lit\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, IndexToString\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.mllib.tree import RandomForest\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT0ylWdGTS_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "692a37d2-e7af-4c02-8c5a-4570e5e0f5b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv60sXk7T1wG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = SparkSession.builder.appName(\"Project - Chicago crime\")\\\n",
        ".config(\"spark.some.config.option\", \"some-value\")\\\n",
        ".config(\"spark.driver.memory\", \"20g\")\\\n",
        ".getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIbfQzS_T946",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crimes_schema = StructType([StructField(\"Date\", StringType(), True ),\n",
        "                            StructField(\"Primary Type\", StringType(), True  ),\n",
        "                            StructField(\"Location Description\", StringType(), True ),\n",
        "                            StructField(\"Arrest\", BooleanType(), True),\n",
        "                            StructField(\"Ward\", StringType(), True),\n",
        "                            StructField(\"Year\", IntegerType(), True),\n",
        "                            StructField(\"Latitude\", DoubleType(), True),\n",
        "                            StructField(\"Longitude\", DoubleType(), True),        \n",
        "                            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIL0kLDjUBlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = spark.read.csv('/content/drive/My Drive/Colab Notebooks/my_csv2.csv',header = True,schema = crimes_schema)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVlXlRekUESE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "02574f28-40e1-40d8-ac68-3b073c0849a3"
      },
      "source": [
        "dataset=data.withColumn(\"Day\", F.split(data.Date, \" \")[0])\n",
        "dataset=dataset.withColumn(\"Day\", F.to_date(dataset.Day, \"MM/dd/yyyy\"))\n",
        "dataset=dataset.withColumn(\"Month\", F.month(dataset.Day))\n",
        "dataset=dataset.withColumn(\"Week\", F.weekofyear(dataset.Day))\n",
        "dataset=dataset.drop('Day')\n",
        "dataset=dataset.drop('Date')\n",
        "dataset.take(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Primary Type='PUBLIC PEACE VIOLATION', Location Description='AIRCRAFT', Arrest=False, Ward='41', Year=2019, Latitude=42.002816387, Longitude=-87.90609433, Month=1, Week=1),\n",
              " Row(Primary Type='BATTERY', Location Description='STREET', Arrest=False, Ward='42', Year=2019, Latitude=41.88336939, Longitude=-87.633860272, Month=3, Week=11),\n",
              " Row(Primary Type='THEFT', Location Description='RESIDENTIAL YARD (FRONT/BACK)', Arrest=False, Ward='4', Year=2019, Latitude=41.825346902, Longitude=-87.606780575, Month=3, Week=11),\n",
              " Row(Primary Type='BATTERY', Location Description='RESIDENCE', Arrest=False, Ward='49', Year=2019, Latitude=42.016541612, Longitude=-87.672499325, Month=3, Week=11),\n",
              " Row(Primary Type='OTHER OFFENSE', Location Description='STREET', Arrest=False, Ward='4', Year=2019, Latitude=41.825298645, Longitude=-87.6069609, Month=3, Week=11)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7LlUwfIUa_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "targetDf = dataset.withColumn(\"Primary Type\", \\\n",
        "              when((dataset[\"Primary Type\"] == 'KIDNAPPING') | (dataset[\"Primary Type\"] == 'HOMICIDE'),'OTHER OFFENSE').otherwise(dataset['Primary Type']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNPqTc60Uh9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "788b21da-ef7b-4d05-f546-ce6cd76da0ec"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, IndexToString, OneHotEncoderEstimator\n",
        "targetDf.printSchema()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Primary Type: string (nullable = true)\n",
            " |-- Location Description: string (nullable = true)\n",
            " |-- Arrest: boolean (nullable = true)\n",
            " |-- Ward: string (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Latitude: double (nullable = true)\n",
            " |-- Longitude: double (nullable = true)\n",
            " |-- Month: integer (nullable = true)\n",
            " |-- Week: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQOAxy_yUqNe",
        "colab_type": "text"
      },
      "source": [
        "**RANDOM FOREST : Use \"Week\" as feature -**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbnaSOmrUrl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "36e32571-cdc4-4339-8098-c8843ebc8b54"
      },
      "source": [
        "vector_assembler = VectorAssembler(inputCols = [\"Week\"], outputCol=\"features\")\n",
        "\n",
        "df_temp = vector_assembler.transform(targetDf)\n",
        "\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\").fit(df_temp)\n",
        "\n",
        "labelIndexer = StringIndexer(inputCol=\"Primary Type\", outputCol=\"indexedLabel\").fit(df_temp)\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
        "                               labels=labelIndexer.labels)\n",
        "\n",
        "(trainingData, testData) = df_temp.randomSplit([0.7, 0.3])\n",
        "rf  = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=100,impurity='gini', maxBins=128)\n",
        "\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf,labelConverter])\n",
        "\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "predictions = model.transform(testData)\n",
        "predictions.select(\"predictedLabel\", \"Primary Type\").show()\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "evaluator2 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "f1 = evaluator2.evaluate(predictions)\n",
        "\n",
        "\n",
        "print(\"accuracy = %g\" % (accuracy))\n",
        "print(\"f1 score = %g\" % (f1))\n",
        "\n",
        "predictions.groupBy(\"predictedLabel\").count().show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------------+\n",
            "|predictedLabel|Primary Type|\n",
            "+--------------+------------+\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "+--------------+------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "accuracy = 0.226515\n",
            "f1 score = 0.0836666\n",
            "+--------------+------+\n",
            "|predictedLabel| count|\n",
            "+--------------+------+\n",
            "|         THEFT|879124|\n",
            "+--------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PPX5A9BUxEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDisgqz2Uyws",
        "colab_type": "text"
      },
      "source": [
        "**RANDOM FOREST : Added more features -**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je2gAGyxU-Gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoderEstimator\n",
        "locationIndexer = StringIndexer(inputCol=\"Location Description\", outputCol=\"indexedLocation\")\\\n",
        "                .fit(targetDf)\\\n",
        "                .transform(targetDf)\n",
        "encoded_data = OneHotEncoderEstimator(inputCols=[\"indexedLocation\"],outputCols=[\"encodedLocation\"])\\\n",
        "        .fit(locationIndexer)\\\n",
        "        .transform(locationIndexer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7fzcQePXkkp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "93e11d48-4863-43b3-8984-7191f812a763"
      },
      "source": [
        "#locationDescIndexer = StringIndexer(inputCol=\"Location Description\", outputCol=\"locDespFeatures\")\n",
        "\n",
        "#loc_des_indexer_model = locationDescInd#exer.fit(targetDf)\n",
        "#loc_des_indexed_data= loc_des_indexer_model.transform(targetDf)\n",
        "\n",
        "vector_assembler = VectorAssembler(inputCols = [\"Latitude\", \"Longitude\", \"Arrest\", \"encodedLocation\"], outputCol=\"features\")\n",
        "df_temp = vector_assembler.transform(encoded_data)\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\").fit(df_temp)\n",
        "\n",
        "\n",
        "labelIndexer = StringIndexer(inputCol=\"Primary Type\", outputCol=\"indexedLabel\").fit(df_temp)\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
        "                               labels=labelIndexer.labels)\n",
        "\n",
        "\n",
        "(trainingData, testData) = df_temp.randomSplit([0.7, 0.3])\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10,impurity='gini', maxBins=32)\n",
        "\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf,labelConverter])\n",
        "\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "predictions = model.transform(testData)\n",
        "predictions.select(\"predictedLabel\", \"Primary Type\").show()\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "evaluator2 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "f1 = evaluator2.evaluate(predictions)\n",
        "\n",
        "\n",
        "print(\"accuracy = %g\" % (accuracy))\n",
        "print(\"f1 score = %g\" % (f1))\n",
        "\n",
        "predictions.groupBy(\"predictedLabel\").count().show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------------+\n",
            "|predictedLabel|Primary Type|\n",
            "+--------------+------------+\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "+--------------+------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "accuracy = 0.291977\n",
            "f1 score = 0.177746\n",
            "+------------------+------+\n",
            "|    predictedLabel| count|\n",
            "+------------------+------+\n",
            "|             THEFT|649816|\n",
            "|           BATTERY|219221|\n",
            "|DECEPTIVE PRACTICE|  1592|\n",
            "|         NARCOTICS|  8195|\n",
            "+------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7xCnWZUhfkc",
        "colab_type": "text"
      },
      "source": [
        "**Using a grid search and 4-fold cross validation -** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tkHVDM7iQZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "targetDf = targetDf.withColumn(\"Ward\", targetDf[\"Ward\"].cast(IntegerType()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCwrviGUmW9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoderEstimator\n",
        "locationIndexer = StringIndexer(inputCol=\"Location Description\", outputCol=\"indexedLocation\")\\\n",
        "                .fit(targetDf)\\\n",
        "                .transform(targetDf)\n",
        "encoded_data = OneHotEncoderEstimator(inputCols=[\"indexedLocation\"],outputCols=[\"encodedLocation\"])\\\n",
        "        .fit(locationIndexer)\\\n",
        "        .transform(locationIndexer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSbJ1ZoPhZ8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "40938b79-d679-43c7-937a-0215f50f6c5f"
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "vector_assembler = VectorAssembler(inputCols = [\"Latitude\", \\\n",
        "                            \"Longitude\", \"Arrest\", \"Week\", \"Ward\",\"encodedLocation\"], outputCol=\"features\")\n",
        "\n",
        "indexed_data = vector_assembler.transform(encoded_data)\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\").fit(indexed_data)\n",
        "\n",
        "\n",
        "labelIndexer = StringIndexer(inputCol=\"Primary Type\", outputCol=\"indexedLabel\").fit(indexed_data)\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
        "                               labels=labelIndexer.labels)\n",
        "\n",
        "\n",
        "(trainingData, testData) = indexed_data.randomSplit([0.7, 0.3])\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
        "\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf,labelConverter])\n",
        "\n",
        "paramGrid = ParamGridBuilder()\\\n",
        "            .addGrid(rf.numTrees, [3,10])\\\n",
        "            .addGrid(rf.maxBins, [32,64])\\\n",
        "            .addGrid(rf.maxDepth, [5,10])\\\n",
        "            .addGrid(rf.impurity,['gini','entropy'])\\\n",
        "            .build()\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "crossval = CrossValidator(\\\n",
        "                          estimator=pipeline,\\\n",
        "                         estimatorParamMaps=paramGrid,\\\n",
        "                         evaluator=evaluator,\\\n",
        "                         numFolds=4)\n",
        "\n",
        "\n",
        "model = crossval.fit(trainingData)\n",
        "\n",
        "\n",
        "predictions = model.transform(testData)\n",
        "predictions.select(\"predictedLabel\", \"Primary Type\").show()\n",
        "\n",
        "evaluator2 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "f1 = evaluator2.evaluate(predictions)\n",
        "print(\"accuracy = %g\" % (accuracy))\n",
        "print(\"f1 score = %g\" % (f1))\n",
        "\n",
        "predictions.groupBy(\"predictedLabel\").count().show()\n",
        "\n",
        "bestPipeline = model.bestModel\n",
        "bestLRModel = bestPipeline.stages[2]\n",
        "bestParams = bestLRModel.extractParamMap()\n",
        "print(\"\\n\".join(\"{}\\t{}\".format(k, v) for k, v in bestParams.items()))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------------+\n",
            "|predictedLabel|Primary Type|\n",
            "+--------------+------------+\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|     NARCOTICS|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|     NARCOTICS|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "|         THEFT|     ASSAULT|\n",
            "+--------------+------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "accuracy = 0.346422\n",
            "f1 score = 0.241841\n",
            "+------------------+------+\n",
            "|    predictedLabel| count|\n",
            "+------------------+------+\n",
            "| CRIMINAL TRESPASS|  1251|\n",
            "|             THEFT|517190|\n",
            "|           BATTERY|171714|\n",
            "|DECEPTIVE PRACTICE|  5971|\n",
            "|         NARCOTICS|166012|\n",
            "|     OTHER OFFENSE|   119|\n",
            "|          BURGLARY| 15416|\n",
            "+------------------+------+\n",
            "\n",
            "RandomForestClassifier_4e7a8711db85177e636d__cacheNodeIds\tFalse\n",
            "RandomForestClassifier_4e7a8711db85177e636d__checkpointInterval\t10\n",
            "RandomForestClassifier_4e7a8711db85177e636d__featureSubsetStrategy\tauto\n",
            "RandomForestClassifier_4e7a8711db85177e636d__featuresCol\tindexedFeatures\n",
            "RandomForestClassifier_4e7a8711db85177e636d__impurity\tentropy\n",
            "RandomForestClassifier_4e7a8711db85177e636d__labelCol\tindexedLabel\n",
            "RandomForestClassifier_4e7a8711db85177e636d__maxBins\t64\n",
            "RandomForestClassifier_4e7a8711db85177e636d__maxDepth\t10\n",
            "RandomForestClassifier_4e7a8711db85177e636d__maxMemoryInMB\t256\n",
            "RandomForestClassifier_4e7a8711db85177e636d__minInfoGain\t0.0\n",
            "RandomForestClassifier_4e7a8711db85177e636d__minInstancesPerNode\t1\n",
            "RandomForestClassifier_4e7a8711db85177e636d__numTrees\t3\n",
            "RandomForestClassifier_4e7a8711db85177e636d__predictionCol\tprediction\n",
            "RandomForestClassifier_4e7a8711db85177e636d__probabilityCol\tprobability\n",
            "RandomForestClassifier_4e7a8711db85177e636d__rawPredictionCol\trawPrediction\n",
            "RandomForestClassifier_4e7a8711db85177e636d__seed\t-8156797869805617175\n",
            "RandomForestClassifier_4e7a8711db85177e636d__subsamplingRate\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}